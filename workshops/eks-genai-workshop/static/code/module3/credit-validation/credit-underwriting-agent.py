# Credit Underwriting Agent for Credit Score Validation - Updated with Image ID Support
# https://python.langchain.com/docs/how_to/migrate_agent/
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from langchain_mcp_adapters.tools import load_mcp_tools
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_openai import ChatOpenAI
from contextlib import asynccontextmanager

import uvicorn
from fastapi import FastAPI, BackgroundTasks, HTTPException, Query, UploadFile, File
import os
from mcp import ClientSession
import asyncio
from langchain_core.prompts import ChatPromptTemplate
import base64
import time
import secrets
import json
from PIL import Image
import io

# Try to import langfuse, but make it optional
try:
    from langfuse.callback import CallbackHandler
    LANGFUSE_AVAILABLE = True
except ImportError:
    print("Warning: Langfuse not available. Tracing will be disabled.")
    LANGFUSE_AVAILABLE = False
    CallbackHandler = None

from utils import store_object, store_image_bytes

def encode_image(image_source):
    """Encode image to base64 string"""
    if isinstance(image_source, bytes):
        image = Image.open(io.BytesIO(image_source))
    elif isinstance(image_source, str):
        # File path
        with open(image_source, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode("utf-8")
    else:
        image = Image.open(image_source)
    
    # Convert RGBA to RGB if necessary (JPEG doesn't support transparency)
    if image.mode in ('RGBA', 'LA'):
        # Create a white background
        background = Image.new('RGB', image.size, (255, 255, 255))
        # Paste the image on the white background
        if image.mode == 'RGBA':
            background.paste(image, mask=image.split()[-1])  # Use alpha channel as mask
        else:
            background.paste(image)
        image = background
    elif image.mode not in ('RGB', 'L'):
        # Convert other modes to RGB
        image = image.convert('RGB')
    
    # Resize image for better processing
    image = image.resize((2400, 1600), Image.Resampling.LANCZOS)
    
    # Save to bytes buffer
    buffer = io.BytesIO()
    image.save(buffer, format="JPEG")
    buffer.seek(0)
    
    # Convert to base64
    return base64.b64encode(buffer.read()).decode("utf-8")

def generate_256_bit_hex_key():
    """
    Generates a cryptographically strong 256-bit random key 
    and returns it as a hexadecimal string.
    """
    # 256 bits is 32 bytes (256 / 8 = 32)
    key_bytes = secrets.token_bytes(32)
    # Convert bytes to a hexadecimal string
    key_hex = key_bytes.hex()
    return key_hex

# Sample credit application image (you can replace with actual credit application image)
credit_app_doc = encode_image("example1.png")  # Replace with actual credit application image
# Store sample image in S3 and get image ID
sample_image_id = generate_256_bit_hex_key()
store_object(credit_app_doc, sample_image_id)

# Model configuration
model_key = os.environ.get("GATEWAY_MODEL_ACCESS_KEY", "")
api_gateway_url = os.environ.get("GATEWAY_URL", "")

# Initialize Langfuse CallbackHandler for Langchain (tracing) - optional
langfuse_handler = None
if LANGFUSE_AVAILABLE:
    langfuse_url = os.environ.get("LANGFUSE_URL", "")
    local_public_key = os.environ.get("LANGFUSE_PUBLIC_KEY", "")
    local_secret_key = os.environ.get("LANGFUSE_SECRET_KEY", "")

    if langfuse_url and local_public_key and local_secret_key:
        os.environ["LANGFUSE_SECRET_KEY"] = local_secret_key
        os.environ["LANGFUSE_HOST"] = langfuse_url
        os.environ["LANGFUSE_PUBLIC_KEY"] = local_public_key
        
        try:
            langfuse_handler = CallbackHandler()
            print("Langfuse tracing enabled")
        except Exception as e:
            print(f"Warning: Could not initialize Langfuse: {e}")
            langfuse_handler = None
    else:
        print("Langfuse configuration incomplete - tracing disabled")
else:
    print("Langfuse tracing disabled - module not available")

# Configure LLM with token limits to avoid rate limiting
llm_model = "bedrock-llama-32"

model = ChatOpenAI(
    model=llm_model, 
    temperature=0, 
    api_key=model_key, 
    base_url=api_gateway_url,
    max_tokens=5000,  # Limit response tokens
    timeout=300       # Add timeout
)

# MCP Servers configuration for credit underwriting with image processing
mcp_address_validator = os.getenv("mcp_address_validator", "http://mcp-address-validator:8000")
mcp_employment_validator = os.getenv("mcp_employment_validator", "http://mcp-employment-validator:8000")
mcp_image_processor = os.getenv("mcp_image_processor", "http://mcp-image-processor:8000")

mcp_servers = {
    "image_processor": {
        "url": mcp_address_validator + "/sse",  # Image processing server
        "transport": "sse",
    },
    "income_employment_validation_service": {
        "url": mcp_employment_validator + "/sse",  # Income and employment validation server
        "transport": "sse",
    },
    "address_validation_service": {
        "url": mcp_image_processor + "/sse",  # Address validation server
        "transport": "sse",
    }
}

app = FastAPI(title="Credit Underwriting Agent with Image ID Support")

# System prompt for the agent - updated for image ID workflow
system_prompt = """You are a helpful AI assistant for credit underwriting and loan processing.

Your task is to process credit applications by analyzing uploaded documents and validating applicant information using the tools provided.

Follow these instructions:
1. First, extract credit application data from the uploaded document using the image processing tools
2. Then validate the extracted information using employment and address validation tools
3. Make a final credit decision based on all validation results
4. Present a comprehensive credit assessment to the user

You are given a set of MCP tools to perform these tasks:
- Use 'extract_credit_application_data' to extract applicant information from documents
- Use 'validate_document_authenticity' to check document quality and authenticity
- Use 'validate_income_employment' to verify employment and income information
- Use 'validate_address' to verify address information

It is critical that you use the tools to process the document and validate the information.
You just need to pass the image_id to the tools, they will handle fetching the image from S3.

Always provide a clear, structured response with your final recommendation.
"""

# Credit application processing prompt - SIMPLIFIED to reduce tokens
user_prompt = """Process this credit application using the provided image ID. Extract key info: Name, Email, Income, Employer, Address, Loan Amount. 
Validate employment and address using tools. Return JSON with APPROVED/REJECTED decision."""

credit_app_user_prompt = HumanMessage(content=[
    {
        "type": "text",
        "text": f"Please process this credit application document. Image ID: {sample_image_id}. {user_prompt}",
    }
])

@app.post("/api/process_credit_application_with_upload")
async def process_credit_application_with_upload(image_file: UploadFile = File(...)):
    """
    Process credit application with uploaded image file
    This endpoint uploads the image to S3 and processes it using image ID
    """
    
    try:
        print("ğŸ”„ Starting credit application processing with uploaded image...")
        
        # Step 1: Read and process the uploaded image
        print("ğŸ“„ Processing uploaded credit application image...")
        image_bytes = await image_file.read()
        
        # Encode image to base64 for storage
        credit_app_image = encode_image(image_bytes)
        
        # Generate unique image ID
        image_id = generate_256_bit_hex_key()
        
        # Store image in S3
        if not store_object(credit_app_image, image_id):
            return {
                "status": "ERROR",
                "message": "Failed to store image in S3",
                "recommendation": "Please try again"
            }
        
        print(f"âœ… Image stored in S3 with ID: {image_id}")
        
        # Step 2: Use MCP client to get tools and process the application
        print("ğŸ”§ Loading MCP tools...")
        client = MultiServerMCPClient(mcp_servers)
        tools = await client.get_tools()
        
        print(f"Available tools: {[tool.name for tool in tools]}")
        
        # Create the agent with tools
        graph = create_react_agent(model, tools, debug=True)
        
        # Configure callbacks - only include langfuse if available
        callbacks = []
        if langfuse_handler is not None:
            callbacks.append(langfuse_handler)
        
        graph = graph.with_config({
            "run_name": "credit_underwriting_agent_with_image_id",
            "callbacks": callbacks,
            "recursion_limit": 10,
        })
        
        # Create user prompt with image ID
        user_prompt_with_id = HumanMessage(content=f"""
        Please process this credit application document and provide a comprehensive credit assessment.
        
        Image ID: {image_id}
        
        Please:
        1. Extract all applicant information from the document
        2. Validate the document authenticity and quality
        3. Verify employment and income information
        4. Verify address information
        5. Provide a final credit decision with reasoning
        
        Return a structured assessment with your recommendation.
        """)
        
        inputs = {
            "messages": [user_prompt_with_id],
            "system": SystemMessage(content=system_prompt)
        }
        
        print("ğŸ¤– Processing credit application with agent...")
        
        final_message = None
        try:
            async for s in graph.astream(inputs, stream_mode="values"):
                message = s["messages"][-1]
                if isinstance(message, tuple):
                    print(message)
                else:
                    message.pretty_print()
                    
                if isinstance(message, AIMessage):
                    final_message = message.content
                    print("Final credit assessment:", final_message)
                    
        except Exception as e:
            if "RateLimitError" in str(e) or "429" in str(e):
                print(f"Rate limit encountered: {e}")
                return {
                    "status": "RATE_LIMITED",
                    "message": "Rate limit encountered. Please try again later.",
                    "image_id": image_id,
                    "recommendation": "Wait a few minutes before retrying"
                }
            else:
                raise e
        
        return {
            "status": "COMPLETED",
            "image_id": image_id,
            "credit_assessment": final_message,
            "processing_note": "Image uploaded to S3 and processed using image ID with MCP tools"
        }
        
    except Exception as e:
        print(f"Error processing credit application: {e}")
        return {
            "status": "ERROR",
            "message": f"Error processing application: {str(e)}",
            "recommendation": "Please check the image format and try again"
        }

@app.post("/api/process_credit_application")
async def process_credit_application():
    """Process credit application using sample image with image ID (legacy endpoint)"""
    
    try:
        print("ğŸ”„ Starting credit application processing with sample image...")
        
        # Use MCP client to get tools and process the application
        print("ğŸ”§ Loading MCP tools...")
        client = MultiServerMCPClient(mcp_servers)
        tools = await client.get_tools()
        
        print(f"Available tools: {[tool.name for tool in tools]}")
        
        # Create the agent with tools
        graph = create_react_agent(model, tools, debug=True)
        
        # Configure callbacks - only include langfuse if available
        callbacks = []
        if langfuse_handler is not None:
            callbacks.append(langfuse_handler)
        
        graph = graph.with_config({
            "run_name": "credit_underwriting_agent_sample",
            "callbacks": callbacks,
            "recursion_limit": 10,
        })
        
        inputs = {
            "messages": [credit_app_user_prompt],
            "system": SystemMessage(content=system_prompt)
        }
        
        final_message = None
        try:
            async for s in graph.astream(inputs, stream_mode="values"):
                message = s["messages"][-1]
                if isinstance(message, tuple):
                    print(message)
                else:
                    message.pretty_print()
                    
                if isinstance(message, AIMessage):
                    final_message = message.content
                    print("Final underwriting decision:", final_message)
                    
        except Exception as e:
            if "RateLimitError" in str(e) or "429" in str(e):
                print(f"Rate limit encountered: {e}")
                return {
                    "status": "RATE_LIMITED",
                    "message": "Rate limit encountered. Try the upload endpoint: /api/process_credit_application_with_upload",
                    "recommendation": "Use /api/process_credit_application_with_upload for better rate limit handling"
                }
            else:
                raise e
                
        return {
            "status": "COMPLETED",
            "image_id": sample_image_id,
            "credit_assessment": final_message,
            "processing_note": "Processed sample image using image ID with MCP tools"
        }
        
    except Exception as e:
        print(f"Error processing credit application: {e}")
        return {
            "status": "ERROR",
            "message": f"Error processing application: {str(e)}",
            "recommendation": "Try /api/process_credit_application_with_upload or /api/validate_application"
        }

@app.post("/api/process_credit_application_by_id")
async def process_credit_application_by_id(image_id: str):
    """
    Process credit application using existing image ID
    This endpoint processes an image that's already stored in S3
    """
    
    try:
        print(f"ğŸ”„ Starting credit application processing with image ID: {image_id}")
        
        # Use MCP client to get tools and process the application
        print("ğŸ”§ Loading MCP tools...")
        client = MultiServerMCPClient(mcp_servers)
        tools = await client.get_tools()
        
        print(f"Available tools: {[tool.name for tool in tools]}")
        
        # Create the agent with tools
        graph = create_react_agent(model, tools, debug=True)
        
        # Configure callbacks - only include langfuse if available
        callbacks = []
        if langfuse_handler is not None:
            callbacks.append(langfuse_handler)
        
        graph = graph.with_config({
            "run_name": "credit_underwriting_agent_by_id",
            "callbacks": callbacks,
            "recursion_limit": 10,
        })
        
        # Create user prompt with image ID
        user_prompt_with_id = HumanMessage(content=f"""
        Please process this credit application document and provide a comprehensive credit assessment.
        
        Image ID: {image_id}
        
        Please:
        1. Extract all applicant information from the document
        2. Validate the document authenticity and quality
        3. Verify employment and income information
        4. Verify address information
        5. Provide a final credit decision with reasoning
        
        Return a structured assessment with your recommendation.
        """)
        
        inputs = {
            "messages": [user_prompt_with_id],
            "system": SystemMessage(content=system_prompt)
        }
        
        print("ğŸ¤– Processing credit application with agent...")
        
        final_message = None
        try:
            async for s in graph.astream(inputs, stream_mode="values"):
                message = s["messages"][-1]
                if isinstance(message, tuple):
                    print(message)
                else:
                    message.pretty_print()
                    
                if isinstance(message, AIMessage):
                    final_message = message.content
                    print("Final credit assessment:", final_message)
                    
        except Exception as e:
            if "RateLimitError" in str(e) or "429" in str(e):
                print(f"Rate limit encountered: {e}")
                return {
                    "status": "RATE_LIMITED",
                    "message": "Rate limit encountered. Please try again later.",
                    "image_id": image_id,
                    "recommendation": "Wait a few minutes before retrying"
                }
            else:
                raise e
        
        return {
            "status": "COMPLETED",
            "image_id": image_id,
            "credit_assessment": final_message,
            "processing_note": "Processed existing image from S3 using image ID with MCP tools"
        }
        
    except Exception as e:
        print(f"Error processing credit application by ID: {e}")
        return {
            "status": "ERROR",
            "message": f"Error processing application: {str(e)}",
            "image_id": image_id,
            "recommendation": "Please check if the image ID exists and try again"
        }

@app.post("/api/extract_data_only")
async def extract_data_only(image_file: UploadFile = File(...)):
    """
    Extract data from credit application without full processing
    This endpoint only extracts and validates document data
    """
    
    try:
        print("ğŸ”„ Starting data extraction from uploaded image...")
        
        # Step 1: Read and process the uploaded image
        print("ğŸ“„ Processing uploaded credit application image...")
        image_bytes = await image_file.read()
        
        # Encode image to base64 for storage
        credit_app_image = encode_image(image_bytes)
        
        # Generate unique image ID
        image_id = generate_256_bit_hex_key()
        
        # Store image in S3
        if not store_object(credit_app_image, image_id):
            return {
                "status": "ERROR",
                "message": "Failed to store image in S3",
                "recommendation": "Please try again"
            }
        
        print(f"âœ… Image stored in S3 with ID: {image_id}")
        
        # Step 2: Use MCP client to get image processing tools only
        print("ğŸ”§ Loading image processing tools...")
        client = MultiServerMCPClient({"image_processor": mcp_servers["image_processor"]})
        tools = await client.get_tools()
        
        # Find the extraction tool
        extraction_tool = None
        validation_tool = None
        
        for tool in tools:
            if "extract_credit_application_data" in tool.name:
                extraction_tool = tool
            elif "validate_document_authenticity" in tool.name:
                validation_tool = tool
        
        # Extract data using MCP tool
        extracted_data = None
        validation_results = None
        
        if extraction_tool:
            print("ğŸ“Š Extracting credit application data...")
            extracted_data = await extraction_tool.ainvoke({"image_id": image_id})
            print("âœ… Data extraction completed")
        
        if validation_tool:
            print("ğŸ” Validating document authenticity...")
            validation_results = await validation_tool.ainvoke({"image_id": image_id})
            print("âœ… Document validation completed")
        
        return {
            "status": "COMPLETED",
            "image_id": image_id,
            "extracted_data": extracted_data,
            "document_validation": validation_results,
            "processing_note": "Data extracted and document validated using image ID with MCP tools"
        }
        
    except Exception as e:
        print(f"Error extracting data: {e}")
        return {
            "status": "ERROR",
            "message": f"Error extracting data: {str(e)}",
            "recommendation": "Please check the image format and try again"
        }

@app.post("/api/process_credit_application_with_delay")
async def process_credit_application_with_delay():
    """Hybrid approach: Extract data from image first, then validate with MCP servers after delay"""
    
    try:
        print("ğŸ”„ Starting hybrid credit application processing...")
        
        # Step 1: Extract data from image using LLM (minimal token usage)
        print("ğŸ“„ Extracting data from credit application image...")
        
        extraction_prompt = """Extract ONLY the following data from this credit application image in JSON format:
        {
            "name": "full name",
            "email": "email address", 
            "income": annual_income_number,
            "employer": "company name",
            "job_title": "job title",
            "employment_years": years_number,
            "address": "street address",
            "city": "city",
            "state": "state",
            "zip": "zip code",
            "loan_amount": loan_amount_number
        }
        Return ONLY the JSON, no other text."""
        
        extraction_message = HumanMessage(content=[
            {
                "type": "text",
                "text": extraction_prompt,
            },
            {
                "type": "image_url",
                "image_url": {
                    "url": "data:image/png;base64," + credit_app_doc
                }
            }
        ])
        
        # Use LLM to extract data from image
        try:
            extraction_response = await model.ainvoke([extraction_message])
            extracted_text = extraction_response.content
            print(f"âœ… Data extracted from image: {extracted_text}")
            
            # Parse the JSON response
            import json
            try:
                applicant_data = json.loads(extracted_text)
                print("âœ… Successfully parsed extracted data")
            except json.JSONDecodeError:
                # Fallback: try to extract JSON from response
                import re
                json_match = re.search(r'\{.*\}', extracted_text, re.DOTALL)
                if json_match:
                    applicant_data = json.loads(json_match.group())
                    print("âœ… Successfully parsed extracted data (with regex)")
                else:
                    raise ValueError("Could not parse JSON from extraction response")
                    
        except Exception as e:
            print(f"âŒ Error extracting data from image: {e}")
            # Fallback to sample data if extraction fails
            applicant_data = {
                "name": "John Michael Doe",
                "email": "john.doe@email.com",
                "income": 75000,
                "employer": "Tech Solutions Inc",
                "job_title": "Software Engineer",
                "employment_years": 3.5,
                "address": "123 Main Street",
                "city": "Anytown",
                "state": "CA",
                "zip": "90210",
                "loan_amount": 8500
            }
            print("âš ï¸ Using fallback sample data due to extraction error")
        
        # Step 2: Get MCP tools and perform validations using extracted data
        print("ğŸ”§ Loading MCP tools...")
        client = MultiServerMCPClient(mcp_servers)
        tools = await client.get_tools()
        
        # Find validation tools
        income_tool = None
        address_tool = None
        
        for tool in tools:
            if "validate_income_employment" in tool.name:
                income_tool = tool
            elif "validate_address" in tool.name:
                address_tool = tool
        
        # Perform MCP validations using extracted data
        employment_result = None
        address_result = None
        
        if income_tool and applicant_data:
            print("ğŸ” Validating employment with extracted data...")
            employment_result = await income_tool.ainvoke({
                "applicant_email": applicant_data.get("email", ""),
                "reported_income": float(applicant_data.get("income", 0)),
                "reported_employer": applicant_data.get("employer", ""),
                "reported_job_title": applicant_data.get("job_title", ""),
                "reported_employment_years": float(applicant_data.get("employment_years", 0))
            })
            print("âœ… Employment validation completed")
        
        if address_tool and applicant_data:
            print("ğŸ  Validating address with extracted data...")
            address_result = await address_tool.ainvoke({
                "street_address": applicant_data.get("address", ""),
                "city": applicant_data.get("city", ""),
                "state": applicant_data.get("state", ""),
                "zip_code": applicant_data.get("zip", "")
            })
            print("âœ… Address validation completed")
        
        # Step 3: Wait for 60 seconds to avoid rate limiting
        print("â³ Waiting 60 seconds before final LLM decision to avoid rate limiting...")
        await asyncio.sleep(60)
        print("âœ… Wait completed, proceeding with final decision...")
        
        # Step 4: Make final decision using LLM with validation results
        validation_summary = f"""
        Applicant Data: {applicant_data}
        Employment Validation: {employment_result}
        Address Validation: {address_result}
        """
        
        decision_prompt = f"""Based on these validation results, make a credit decision:
        {validation_summary}
        
        Return JSON: {{"decision": "APPROVED/REJECTED", "score": 300-850, "reason": "brief reason"}}"""
        
        # Make final LLM call with minimal tokens
        try:
            print("ğŸ¤– Making final credit decision...")
            decision_message = HumanMessage(content=decision_prompt)
            decision_response = await model.ainvoke([decision_message])
            final_decision = decision_response.content
            print("âœ… Final decision completed")
            
        except Exception as e:
            if "RateLimitError" in str(e) or "429" in str(e):
                print(f"âš ï¸ Rate limit encountered in final decision: {e}")
                # Make decision based on validation results
                employment_passed = employment_result and ("PASSED" in str(employment_result) or "Valid" in str(employment_result))
                address_passed = address_result and ("VALID" in str(address_result) or "Valid" in str(address_result))
                
                if employment_passed and address_passed:
                    final_decision = '{"decision": "APPROVED", "score": 780, "reason": "All validations passed"}'
                else:
                    final_decision = '{"decision": "REJECTED", "score": 650, "reason": "Validation failures detected"}'
                print("âœ… Decision made based on validation results (rate limit fallback)")
            else:
                raise e
        
        return {
            "extracted_data": applicant_data,
            "validation_results": {
                "employment": employment_result,
                "address": address_result
            },
            "final_decision": final_decision,
            "processing_note": "Hybrid approach: Image extraction â†’ MCP validation â†’ Final decision with 60s delay"
        }
        
    except Exception as e:
        print(f"âŒ Error in hybrid processing: {e}")
        return {
            "status": "ERROR",
            "message": f"Error in hybrid processing: {str(e)}",
            "recommendation": "Please try again or use /api/validate_application"
        }

@app.post("/api/validate_application")
async def validate_application():
    """Hybrid validation: Extract data from image, then validate with MCP servers (no final LLM decision)"""
    
    try:
        print("ğŸ”„ Starting hybrid validation (no LLM decision)...")
        
        # Step 1: Extract data from image using LLM
        print("ğŸ“„ Extracting data from credit application image...")
        
        extraction_prompt = """Extract ONLY the following data from this credit application image in JSON format:
        {
            "name": "full name",
            "email": "email address", 
            "income": annual_income_number,
            "employer": "company name",
            "job_title": "job title",
            "employment_years": years_number,
            "address": "street address",
            "city": "city",
            "state": "state",
            "zip": "zip code",
            "loan_amount": loan_amount_number
        }
        Return ONLY the JSON, no other text."""
        
        extraction_message = HumanMessage(content=[
            {
                "type": "text",
                "text": extraction_prompt,
            },
            {
                "type": "image_url",
                "image_url": {
                    "url": "data:image/png;base64," + credit_app_doc
                }
            }
        ])
        
        # Use LLM to extract data from image
        try:
            extraction_response = await model.ainvoke([extraction_message])
            extracted_text = extraction_response.content
            print(f"âœ… Data extracted from image: {extracted_text}")
            
            # Parse the JSON response
            import json
            try:
                applicant_data = json.loads(extracted_text)
                print("âœ… Successfully parsed extracted data")
            except json.JSONDecodeError:
                # Fallback: try to extract JSON from response
                import re
                json_match = re.search(r'\{.*\}', extracted_text, re.DOTALL)
                if json_match:
                    applicant_data = json.loads(json_match.group())
                    print("âœ… Successfully parsed extracted data (with regex)")
                else:
                    raise ValueError("Could not parse JSON from extraction response")
                    
        except Exception as e:
            print(f"âŒ Error extracting data from image: {e}")
            # Fallback to sample data if extraction fails
            applicant_data = {
                "name": "John Michael Doe",
                "email": "john.doe@email.com",
                "income": 75000,
                "employer": "Tech Solutions Inc",
                "job_title": "Software Engineer",
                "employment_years": 3.5,
                "address": "123 Main Street",
                "city": "Anytown",
                "state": "CA",
                "zip": "90210",
                "loan_amount": 8500
            }
            print("âš ï¸ Using fallback sample data due to extraction error")
        
        # Step 2: Use the MCP client to get tools
        print("ğŸ”§ Loading MCP tools...")
        client = MultiServerMCPClient(mcp_servers)
        tools = await client.get_tools()
        
        # Find the validation tools
        income_tool = None
        address_tool = None
        
        for tool in tools:
            if "validate_income_employment" in tool.name:
                income_tool = tool
            elif "validate_address" in tool.name:
                address_tool = tool
        
        # Perform validations using extracted data
        employment_result = None
        address_result = None
        
        if income_tool:
            try:
                print("ğŸ” Validating employment with extracted data...")
                employment_result = await income_tool.ainvoke({
                    "applicant_email": applicant_data.get("email", ""),
                    "reported_income": float(applicant_data.get("income", 0)),
                    "reported_employer": applicant_data.get("employer", ""),
                    "reported_job_title": applicant_data.get("job_title", ""),
                    "reported_employment_years": float(applicant_data.get("employment_years", 0))
                })
                print("âœ… Employment validation completed")
            except Exception as e:
                print(f"Employment validation error: {e}")
        
        if address_tool:
            try:
                print("ğŸ  Validating address with extracted data...")
                address_result = await address_tool.ainvoke({
                    "street_address": applicant_data.get("address", ""),
                    "city": applicant_data.get("city", ""),
                    "state": applicant_data.get("state", ""),
                    "zip_code": applicant_data.get("zip", "")
                })
                print("âœ… Address validation completed")
            except Exception as e:
                print(f"Address validation error: {e}")
        
        # Calculate simple decision based on validation results (no LLM needed)
        employment_passed = employment_result and ("PASSED" in str(employment_result) or "Valid" in str(employment_result))
        address_passed = address_result and ("VALID" in str(address_result) or "Valid" in str(address_result))
        
        # Calculate debt-to-income ratio
        annual_income = applicant_data.get("income", 1)
        loan_amount = applicant_data.get("loan_amount", 0)
        debt_to_income = (loan_amount * 12) / annual_income * 100 if annual_income > 0 else 100
        
        # Make decision based on validation results
        if employment_passed and address_passed and debt_to_income < 20:
            decision = "APPROVED"
            credit_score = 780
            risk_level = "LOW"
        elif employment_passed and address_passed:
            decision = "APPROVED"
            credit_score = 720
            risk_level = "MEDIUM"
        else:
            decision = "REJECTED"
            credit_score = 650
            risk_level = "HIGH"
        
        return {
            "status": "COMPLETED",
            "extracted_data": applicant_data,
            "credit_decision": decision,
            "preliminary_credit_score": credit_score,
            "risk_level": risk_level,
            "validation_results": {
                "employment_verification": "PASSED" if employment_passed else "FAILED",
                "address_verification": "PASSED" if address_passed else "FAILED",
                "debt_to_income_ratio": f"{debt_to_income:.1f}%"
            },
            "employment_details": employment_result,
            "address_details": address_result,
            "loan_details": {
                "requested_amount": applicant_data.get("loan_amount", 0),
                "purpose": "As specified in application",
                "recommended_terms": "36 months" if decision == "APPROVED" else "N/A"
            },
            "processing_note": "Hybrid approach: Image extraction â†’ MCP validation â†’ Rule-based decision (no final LLM)"
        }
        
    except Exception as e:
        print(f"Validation error: {e}")
        return {
            "status": "ERROR",
            "message": f"Validation failed: {str(e)}",
            "recommendation": "Please check system status and try again."
        }

@app.get("/api/tools")
async def list_available_tools():
    """List all available MCP tools"""
    try:
        client = MultiServerMCPClient(mcp_servers)
        tools = await client.get_tools()
        
        tool_info = []
        for tool in tools:
            tool_info.append({
                "name": tool.name,
                "description": tool.description,
                "server": "determined_by_port"  # Could be enhanced to show which server
            })
        
        return {
            "status": "success",
            "available_tools": tool_info,
            "total_tools": len(tool_info)
        }
    except Exception as e:
        return {
            "status": "error",
            "message": f"Error listing tools: {str(e)}"
        }

@app.get("/api/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "service": "credit_underwriting_agent_with_image_id"}

if __name__ == "__main__":
    print("Starting Credit Underwriting Agent with Image ID Support...")
    print("Available endpoints:")
    print("- POST /api/process_credit_application_with_upload - Upload and process new image")
    print("- POST /api/process_credit_application_by_id - Process existing image by ID")
    print("- POST /api/extract_data_only - Extract data without full processing")
    print("- POST /api/process_credit_application - Process sample image (legacy)")
    print("- GET /api/tools - List available MCP tools")
    print("- GET /api/health - Health check")
    
    uvicorn.run("credit-underwriting-agent:app", host="0.0.0.0", port=8080, reload=True)
