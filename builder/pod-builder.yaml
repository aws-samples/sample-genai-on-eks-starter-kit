apiVersion: v1
kind: Pod
metadata:
  name: builder
  namespace: vllm
  # namespace: sglang
  # namespace: tgi
spec:
  nodeSelector:
    karpenter.sh/nodepool: custom
    kubernetes.io/arch: amd64
    karpenter.sh/capacity-type: on-demand
    node.kubernetes.io/instance-type: r7i.2xlarge
  containers:
    - name: ubuntu
      image: ubuntu
      command: ["sleep", "604800"]
      tty: true
      stdin: true
      env:
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-token
              key: token
        - name: HF_HOME
          value: /root/.cache/huggingface
      resources:
        requests:
          cpu: 3.6
          memory: 29Gi
        limits:
          memory: 60Gi
      volumeMounts:
        - name: huggingface-cache
          mountPath: /root/.cache/huggingface
        # - name: neuron-cache
        #   mountPath: /root/.cache/neuron
  volumes:
    - name: huggingface-cache
      persistentVolumeClaim:
        claimName: huggingface-cache
    # - name: neuron-cache
    #   persistentVolumeClaim:
    #     claimName: neuron-cache
  tolerations:
    - key: karpenter.sh/nodepool
      operator: Equal
      value: custom
      effect: NoSchedule
# Terminal 1
# apt update && DEBIAN_FRONTEND=noninteractive apt install -y python3-venv python3-full htop
# python3 -m venv ~/myenv
# source ~/myenv/bin/activate
# pip install -U "huggingface_hub"
# hf download Qwen/Qwen3-4B-Instruct-2507
# hf download Qwen/Qwen3-4B-Thinking-2507
# hf download Qwen/Qwen3-8B
# hf download deepseek-ai/DeepSeek-R1-0528-Qwen3-8B
# hf download Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8
# hf download openai/gpt-oss-120b
# hf download moonshotai/Kimi-K2-Instruct
# Terminal 2
# cd /root/.cache/huggingface/hub
# htop
